{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "I9Hk-z11XDkX",
        "outputId": "45123bd2-de48-479f-ba99-e4253bcbd5c1"
      },
      "outputs": [],
      "source": [
        "!nvidia-smi\n",
        "import os\n",
        "HOME = os.getcwd()\n",
        "print(HOME)\n",
        "from IPython import display\n",
        "display.clear_output()\n",
        "import ultralytics\n",
        "ultralytics.checks()\n",
        "from IPython import display\n",
        "display.clear_output()\n",
        "import sys\n",
        "sys.path.append(f\"{HOME}/ByteTrack\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "supervision.__version__: 0.1.0\n",
            "YOLOv8x summary (fused): 268 layers, 68200608 parameters, 0 gradients, 257.8 GFLOPs\n"
          ]
        }
      ],
      "source": [
        "import yolox\n",
        "print(\"yolox.__version__:\", yolox.__version__)\n",
        "# from yolox.tracker.byte_tracker import BYTETracker, STrack\n",
        "from onemetric.cv.utils.iou import box_iou_batch\n",
        "from dataclasses import dataclass\n",
        "@dataclass(frozen=True)\n",
        "class BYTETrackerArgs:\n",
        "    track_thresh: float = 0.25\n",
        "    track_buffer: int = 30\n",
        "    match_thresh: float = 0.8\n",
        "    aspect_ratio_thresh: float = 3.0\n",
        "    min_box_area: float = 1.0\n",
        "    mot20: bool = False\n",
        "from IPython import display\n",
        "display.clear_output()\n",
        "import supervision\n",
        "print(\"supervision.__version__:\", supervision.__version__)\n",
        "from supervision.draw.color import ColorPalette\n",
        "# from supervision.geometry.dataclasses import Point\n",
        "# from supervision.video.dataclasses import VideoInfo\n",
        "# from supervision.video.source import get_video_frames_generator\n",
        "# from supervision.video.sink import VideoSink\n",
        "# from supervision.notebook.utils import show_frame_in_notebook\n",
        "from supervision.tools.detections import Detections, BoxAnnotator\n",
        "# from supervision.tools.line_counter import LineCounter, LineCounterAnnotator\n",
        "# settings\n",
        "MODEL = \"yolov8x.pt\"\n",
        "from ultralytics import YOLO\n",
        "model = YOLO(MODEL)\n",
        "model.fuse()\n",
        "CLASS_NAMES_DICT = model.model.names\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "0: 640x608 1 person, 11 cars, 2 buss, 1892.0ms\n",
            "Speed: 7.9ms preprocess, 1892.0ms inference, 3.6ms postprocess per image at shape (1, 3, 640, 608)\n",
            "Number of car: 11\n",
            "{'car': 11}\n",
            "Number of motorcycle: 0\n",
            "{'car': 11, 'motorcycle': 0}\n",
            "Number of bus: 2\n",
            "{'car': 11, 'motorcycle': 0, 'bus': 2}\n",
            "Number of truck: 0\n",
            "{'car': 11, 'motorcycle': 0, 'bus': 2, 'truck': 0}\n",
            "\n",
            "0: 608x640 12 cars, 1933.5ms\n",
            "Speed: 5.0ms preprocess, 1933.5ms inference, 3.0ms postprocess per image at shape (1, 3, 608, 640)\n",
            "Number of car: 12\n",
            "{'car': 12}\n",
            "Number of motorcycle: 0\n",
            "{'car': 12, 'motorcycle': 0}\n",
            "Number of bus: 0\n",
            "{'car': 12, 'motorcycle': 0, 'bus': 0}\n",
            "Number of truck: 0\n",
            "{'car': 12, 'motorcycle': 0, 'bus': 0, 'truck': 0}\n",
            "\n",
            "0: 448x640 8 cars, 1 bus, 1 truck, 1444.3ms\n",
            "Speed: 4.8ms preprocess, 1444.3ms inference, 2.0ms postprocess per image at shape (1, 3, 448, 640)\n",
            "Number of car: 8\n",
            "{'car': 8}\n",
            "Number of motorcycle: 0\n",
            "{'car': 8, 'motorcycle': 0}\n",
            "Number of bus: 1\n",
            "{'car': 8, 'motorcycle': 0, 'bus': 1}\n",
            "Number of truck: 1\n",
            "{'car': 8, 'motorcycle': 0, 'bus': 1, 'truck': 1}\n",
            "\n",
            "0: 640x448 1 person, 6 cars, 1 motorcycle, 3 buss, 1 truck, 1470.6ms\n",
            "Speed: 6.2ms preprocess, 1470.6ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 448)\n",
            "Number of car: 6\n",
            "{'car': 6}\n",
            "Number of motorcycle: 1\n",
            "{'car': 6, 'motorcycle': 1}\n",
            "Number of bus: 3\n",
            "{'car': 6, 'motorcycle': 1, 'bus': 3}\n",
            "Number of truck: 1\n",
            "{'car': 6, 'motorcycle': 1, 'bus': 3, 'truck': 1}\n",
            "[{'car': 11, 'motorcycle': 0, 'bus': 2, 'truck': 0}, {'car': 12, 'motorcycle': 0, 'bus': 0, 'truck': 0}, {'car': 8, 'motorcycle': 0, 'bus': 1, 'truck': 1}, {'car': 6, 'motorcycle': 1, 'bus': 3, 'truck': 1}]\n"
          ]
        }
      ],
      "source": [
        "# class_ids of interest - car, motorcycle, bus and truck\n",
        "CLASS_ID = [2, 3, 5, 7]\n",
        "from supervision.tools.detections import Detections, BoxAnnotator\n",
        "import cv2\n",
        "\n",
        "box_annotator = BoxAnnotator(color=ColorPalette(), thickness=1, text_thickness=1, text_scale=0.5)\n",
        "dict_list = []\n",
        "\n",
        "def process_images():\n",
        "    image_paths = [r\"C:\\Users\\Shashank\\Desktop\\deleteme\\1.jpg\", r\"C:\\Users\\Shashank\\Desktop\\deleteme\\2.jpg\", r\"C:\\Users\\Shashank\\Desktop\\deleteme\\3.jpg\", r\"C:\\Users\\Shashank\\Desktop\\deleteme\\img5.jpeg.jpg\"]\n",
        "    images = [cv2.imread(path) for path in image_paths]\n",
        "\n",
        "    for image in images:\n",
        "        # Model prediction on single image and conversion to supervision Detections\n",
        "        results = model(image)\n",
        "        detections = Detections(\n",
        "            xyxy=results[0].boxes.xyxy.cpu().numpy(),\n",
        "            confidence=results[0].boxes.conf.cpu().numpy(),\n",
        "            class_id=results[0].boxes.cls.cpu().numpy().astype(int)\n",
        "        )\n",
        "\n",
        "        object_counts = {class_name: 0 for class_name in CLASS_NAMES_DICT.values()}\n",
        "        labels = [\n",
        "            f\"{CLASS_NAMES_DICT[class_id]} {confidence:0.2f}\"\n",
        "            for _, confidence, class_id, tracker_id\n",
        "            in detections\n",
        "        ]\n",
        "\n",
        "        temp_dict = {}  # Create a new dictionary for each image\n",
        "        for _, confidence, class_id, tracker_id in detections:\n",
        "            class_name = CLASS_NAMES_DICT[class_id]\n",
        "            if class_id in [2, 3, 5, 7]:\n",
        "                object_counts[class_name] = object_counts.get(class_name, 0) + 1\n",
        "\n",
        "        for class_id in [2, 3, 5, 7]:\n",
        "            class_name = CLASS_NAMES_DICT[class_id]\n",
        "            count = object_counts.get(class_name, 0)\n",
        "            print(f\"Number of {class_name}: {count}\")\n",
        "            temp_dict[class_name] = count\n",
        "            print(temp_dict)\n",
        "\n",
        "        dict_list.append(temp_dict)  # Append the new dictionary to dict_list\n",
        "\n",
        "        # Annotate and display the image\n",
        "        annotated_image = box_annotator.annotate(frame=image, detections=detections, labels=labels)\n",
        "        # %matplotlib inline\n",
        "        cv2.imshow(\"Image\",annotated_image)\n",
        "\n",
        "    return dict_list\n",
        "\n",
        "print(process_images())\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
